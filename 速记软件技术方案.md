# 速记软件（QuickMemo）— 完整技术方案

## 一、整体架构

采用前后端分离 + 微服务思路，分为三层：React 前端、Python 业务后端（FastAPI）、数据层（MySQL + Neo4j + Redis）。LangChain/LangGraph 作为 AI 中枢贯穿全链路。

```
┌─────────────────────────────────────────────────────────┐
│                    React 前端 (Vite + Ant Design)        │
│   注册/偏好 │ 分类管理 │ 速记编辑 │ 录音 │ 搜索 │ 展示  │
└──────────────────────┬──────────────────────────────────┘
                       │ REST / WebSocket
┌──────────────────────▼──────────────────────────────────┐
│              FastAPI 业务网关层 (Python)                  │
│  ┌──────────┐ ┌──────────┐ ┌───────────┐ ┌───────────┐ │
│  │用户服务   │ │速记服务   │ │分类服务    │ │搜索服务    │ │
│  └──────────┘ └──────────┘ └───────────┘ └───────────┘ │
│  ┌──────────────────────────────────────────────────┐   │
│  │         LangChain / LangGraph Agent 层            │   │
│  │  分类生成Agent │ 标签提取Agent │ 关系发现Agent     │   │
│  │  事件关联Agent │ 语义搜索Agent                     │   │
│  └──────────────────────────────────────────────────┘   │
│  ┌──────────────────────────────────────────────────┐   │
│  │         Celery + Redis (异步任务 & 定时任务)       │   │
│  └──────────────────────────────────────────────────┘   │
│  ┌──────────────────────────────────────────────────┐   │
│  │         Whisper 语音识别服务                       │   │
│  └──────────────────────────────────────────────────┘   │
└──────────────────────┬──────────────────────────────────┘
                       │
┌──────────────────────▼──────────────────────────────────┐
│                      数据层                              │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐              │
│  │  MySQL    │  │  Neo4j   │  │  Redis   │              │
│  │ 用户/会话 │  │ 知识图谱  │  │ 缓存/队列│              │
│  └──────────┘  └──────────┘  └──────────┘              │
└─────────────────────────────────────────────────────────┘
```

## 二、技术选型与可直接使用的开源框架

### 2.1 核心框架一览

| 层级 | 技术选型 | 说明 |
|------|---------|------|
| 前端 | Vite + React + TypeScript + Ant Design | Ant Design 组件齐全，适合中后台+笔记场景 |
| 富文本编辑器 | **Tiptap** (基于 ProseMirror) | 开源、可扩展、支持协作编辑，适合速记场景 |
| 图谱可视化 | **@neo4j-nvl/react** 或 **react-force-graph** | Neo4j 官方提供的 React 图可视化组件 |
| 后端框架 | **FastAPI** (Python 3.11+) | 异步高性能，与 LangChain 生态无缝衔接 |
| AI 框架 | **LangChain** + **LangGraph** | LangGraph 构建多步骤 Agent 工作流 |
| 知识图谱构建 | **langchain-neo4j** (LLMGraphTransformer) | 从文本自动提取实体和关系写入 Neo4j |
| 图谱查询 | **GraphCypherQAChain** | 自然语言转 Cypher 查询，用于搜索模块 |
| 结构化输出 | **LangChain with_structured_output + Pydantic** | 强制 LLM 输出符合预定义 schema |
| 语音识别 | **OpenAI Whisper** (faster-whisper) | faster-whisper 是 CTranslate2 加速版，速度快 4 倍 |
| ORM | **SQLAlchemy** + **Alembic** | MySQL ORM 及数据库迁移 |
| Neo4j 驱动 | **neo4j-python-driver** | 官方异步驱动 |
| 缓存/消息队列 | **Redis** + **redis-py** | 会话缓存、热数据缓存、Celery Broker |
| 异步/定时任务 | **Celery** + **celery-beat** | 异步处理 AI 任务 + 定时任务调度 |
| 容器化 | **Docker** + **docker-compose** | 一键启动全部服务 |

### 2.2 可以直接拿来用的开源项目

**1. langchain-neo4j（核心依赖）**
- 地址：https://github.com/langchain-ai/langchain-neo4j
- 提供 `Neo4jGraph`、`LLMGraphTransformer`、`GraphCypherQAChain`、`Neo4jVector` 等核心组件
- 直接用于：知识图谱构建、图谱查询、向量检索

**2. Microsoft GraphRAG（架构参考 + 部分代码复用）**
- 地址：https://github.com/microsoft/graphrag
- 提供"从局部到全局"的分层检索策略
- 可借鉴其社区检测（Leiden 算法）对笔记自动聚类
- 其 LLMGraphTransformer 的 prompt 模板可直接复用

**3. Neo4j LLM Knowledge Graph Builder（参考）**
- 地址：https://github.com/neo4j-labs/llm-graph-builder
- Neo4j 官方实验室项目，从非结构化数据构建知识图谱的完整应用
- 可参考其前端交互设计和图谱可视化方案

**4. faster-whisper（语音识别）**
- 地址：https://github.com/SYSTRAN/faster-whisper
- CTranslate2 加速的 Whisper 实现，推理速度比原版快 4 倍
- 直接部署为语音转文字微服务

**5. Tiptap 编辑器**
- 地址：https://github.com/ueberdosis/tiptap
- 基于 ProseMirror，支持 Markdown、富文本、协作编辑
- React 组件可直接集成，通过扩展实现 AI 辅助写作

**6. BAML（可选，提升抽取成功率）**
- 地址：https://github.com/BoundaryML/baml
- 模糊解析技术，将 LLM 知识抽取成功率从 25% 提升到 99.4%
- 适合使用本地模型时的兜底方案

## 三、数据模型设计

### 3.1 MySQL 数据模型（用户/会话/元数据）

```sql
-- 用户表
CREATE TABLE users (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    username VARCHAR(64) UNIQUE NOT NULL,
    password_hash VARCHAR(256) NOT NULL,
    email VARCHAR(128),
    preferences JSON,          -- 用户偏好（注册时选的大分类）
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 会话表
CREATE TABLE sessions (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    token VARCHAR(512) NOT NULL,
    expires_at TIMESTAMP NOT NULL,
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- 速记元数据表（原文存这里，图谱信息存 Neo4j）
CREATE TABLE memos (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    type ENUM('quick_note', 'event') NOT NULL,  -- 速记 or 事件
    title VARCHAR(256),
    content TEXT NOT NULL,               -- 原始内容
    audio_url VARCHAR(512),              -- 关联录音文件地址
    status ENUM('active', 'archived', 'deleted') DEFAULT 'active',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- 用户偏好分类记录
CREATE TABLE user_category_preferences (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    category_level TINYINT NOT NULL,      -- 1=一级分类, 2=二级分类
    category_name VARCHAR(128) NOT NULL,
    selected BOOLEAN DEFAULT TRUE,
    FOREIGN KEY (user_id) REFERENCES users(id)
);
```

### 3.2 Neo4j 图数据模型（知识图谱核心）

这是整个系统最关键的数据模型。围绕用户需求设计了四种核心维度：分类(Category)、标签(Tag)、关系(Relation)、事件(Event)。

```
节点类型 (Labels):
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
(:User)           - 用户节点
(:Memo)           - 速记节点（与 MySQL memos 表通过 memo_id 关联）
(:Event)          - 事件节点（长期任务/重大事件/性格标记等）
(:Category)       - 分类节点（层级结构：一级/二级）
(:Tag)            - 标签节点（由 LLM 自动生成）
(:Entity)         - 实体节点（人物/地点/组织/概念等，LLM 抽取）
(:TimePeriod)     - 时间节点（按天/周/月组织，用于时间维度展示）

关系类型 (Relationships):
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
(:User)-[:OWNS]->(:Memo)                    用户拥有速记
(:User)-[:OWNS]->(:Event)                   用户拥有事件
(:User)-[:PREFERS]->(:Category)             用户偏好分类

(:Memo)-[:BELONGS_TO]->(:Category)          速记归属分类
(:Memo)-[:HAS_TAG]->(:Tag)                  速记拥有标签
(:Memo)-[:MENTIONS]->(:Entity)              速记提及实体
(:Memo)-[:HAPPENED_ON]->(:TimePeriod)       速记的时间归属
(:Memo)-[:RELATED_TO {score, reason}]->(:Memo)  速记间的关联（带相关度和原因）
(:Memo)-[:LINKED_TO]->(:Event)              速记关联到事件

(:Event)-[:BELONGS_TO]->(:Category)         事件归属分类
(:Event)-[:HAS_TAG]->(:Tag)                 事件拥有标签
(:Event)-[:MENTIONS]->(:Entity)             事件提及实体
(:Event)-[:RELATED_TO {score, reason}]->(:Event)  事件间的关联
(:Event)-[:HAPPENED_ON]->(:TimePeriod)      事件的时间归属

(:Category)-[:CHILD_OF]->(:Category)        分类的层级关系
(:Entity)-[:RELATED_TO]->(:Entity)          实体间的关系（如：人物-就职于-公司）
(:Tag)-[:CO_OCCURS {weight}]->(:Tag)        标签共现关系（用于推荐）
```

完整的 Cypher 建模示例：

```cypher
// 创建索引
CREATE INDEX FOR (u:User) ON (u.user_id);
CREATE INDEX FOR (m:Memo) ON (m.memo_id);
CREATE INDEX FOR (e:Event) ON (e.event_id);
CREATE INDEX FOR (c:Category) ON (c.name);
CREATE INDEX FOR (t:Tag) ON (t.name);
CREATE INDEX FOR (en:Entity) ON (en.name);
CREATE INDEX FOR (tp:TimePeriod) ON (tp.date);

// 创建全文索引用于搜索
CREATE FULLTEXT INDEX memoContent FOR (m:Memo) ON EACH [m.title, m.content];
CREATE FULLTEXT INDEX eventContent FOR (e:Event) ON EACH [e.title, e.description];

// 向量索引（用于语义搜索）
CALL db.index.vector.createNodeIndex(
  'memo_embeddings', 'Memo', 'embedding', 1536, 'cosine'
);

// 示例数据
CREATE (u:User {user_id: 1, name: '张三'})
CREATE (c1:Category {name: '学习资料', level: 1})
CREATE (c2:Category {name: 'Python编程', level: 2})-[:CHILD_OF]->(c1)
CREATE (memo:Memo {
    memo_id: 101,
    title: '学习LangChain笔记',
    content: '今天学了LangChain的Agent机制...',
    created_at: datetime()
})
CREATE (event:Event {
    event_id: 201,
    title: '完成AI项目',
    description: '用LangChain+Neo4j搭建知识图谱系统',
    status: 'in_progress',
    priority: 'high',
    deadline: date('2024-06-01')
})
CREATE (tag1:Tag {name: 'LangChain'})
CREATE (tag2:Tag {name: 'AI'})
CREATE (entity:Entity {name: 'LangChain', type: 'Technology'})

CREATE (u)-[:OWNS]->(memo)
CREATE (u)-[:OWNS]->(event)
CREATE (memo)-[:BELONGS_TO]->(c2)
CREATE (memo)-[:HAS_TAG]->(tag1)
CREATE (memo)-[:HAS_TAG]->(tag2)
CREATE (memo)-[:MENTIONS]->(entity)
CREATE (memo)-[:LINKED_TO]->(event)
```

### 3.3 Redis 用途

```
用途一：会话缓存
  session:{token} -> {user_id, expires_at}    TTL=24h

用途二：热数据缓存
  user:{id}:recent_memos -> List<memo_id>     最近速记 ID 列表
  user:{id}:categories -> JSON                用户分类树缓存
  memo:{id}:tags -> Set<tag_name>             速记标签缓存

用途三：Celery Broker
  作为 Celery 的消息队列 broker，驱动异步 AI 任务

用途四：限流
  rate_limit:{user_id}:{api} -> count         API 调用频率限制
```

## 四、各模块详细设计

### 4.1 注册模块

流程：用户注册 → 选择一级偏好分类 → LangChain 生成二级分类 → 用户选择（跳过则全选）→ 写入 MySQL + Neo4j

```python
# LangChain 生成二级分类的实现思路
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

class SubCategories(BaseModel):
    categories: list[str]  # 二级分类列表
    descriptions: dict[str, str]  # 每个分类的简短描述

llm = ChatOpenAI(model="gpt-4o-mini").with_structured_output(SubCategories)

prompt = ChatPromptTemplate.from_messages([
    ("system", "你是一个智能分类助手。根据用户选择的一级兴趣分类，"
               "生成 8-12 个具体的二级分类。分类应该有实际意义且互不重叠。"),
    ("human", "用户选择的一级分类是：{primary_categories}\n"
              "请生成对应的二级分类。")
])

chain = prompt | llm

# 调用示例
result = chain.invoke({
    "primary_categories": "学习资料, 运动"
})
# 返回: SubCategories(categories=["Python编程", "数据结构", "跑步训练", ...], ...)
```

一级分类是预定义的固定列表（学习资料、刊物、运动、工作项目、生活记录、兴趣爱好等）。二级分类由 LLM 根据一级分类动态生成，用户确认后写入 Neo4j 的 Category 节点并建立层级关系。

### 4.2 分类模块

你提到分类模块有四个维度：分类(Category)、标签(Tag)、关系(Relation)、事件(Event)。我的设计如下：

**四维度检索模型：**

```
                    ┌──────────┐
         ┌─────────│  用户     │─────────┐
         │         └──────────┘          │
         │PREFERS                    OWNS│
         ▼                               ▼
    ┌──────────┐                    ┌──────────┐
    │ 分类      │◄──BELONGS_TO──────│ 速记/事件 │
    │ Category  │                   │ Memo/Event│
    └──────────┘                    └──────────┘
         │                           │    │    │
      CHILD_OF                  HAS_TAG  │  MENTIONS
         │                        │      │      │
         ▼                        ▼      │      ▼
    ┌──────────┐             ┌──────┐    │  ┌──────────┐
    │ 子分类    │             │ 标签  │    │  │ 实体      │
    └──────────┘             │ Tag  │    │  │ Entity   │
                             └──────┘    │  └──────────┘
                                         │
                                    LINKED_TO / RELATED_TO
                                         │
                                         ▼
                                    ┌──────────┐
                                    │ 关联内容   │
                                    │ (其他速记/事件)│
                                    └──────────┘
```

用户从任何一个维度进入，都能找到关联内容：

- 从分类进入：某分类下所有速记和事件
- 从标签进入：拥有该标签的所有内容，以及共现标签推荐
- 从实体进入：提及该实体的所有内容，以及该实体关联的其他实体
- 从事件进入：该事件关联的所有速记，以及相关事件

**每次新增内容后的 LLM 处理流程（LangGraph 工作流）：**

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict

class MemoProcessState(TypedDict):
    memo_id: int
    content: str
    memo_type: str  # 'quick_note' or 'event'
    categories: list[str]
    tags: list[str]
    entities: list[dict]
    related_items: list[dict]

def classify_node(state: MemoProcessState) -> MemoProcessState:
    """节点1: 分类 — 匹配现有分类或建议新分类"""
    ...

def extract_tags_entities_node(state: MemoProcessState) -> MemoProcessState:
    """节点2: 提取标签和实体"""
    ...

def find_relations_node(state: MemoProcessState) -> MemoProcessState:
    """节点3: 查找关联内容（速记关联速记，事件关联事件/速记）"""
    ...

def write_graph_node(state: MemoProcessState) -> MemoProcessState:
    """节点4: 将所有结果写入 Neo4j"""
    ...

# 构建工作流
workflow = StateGraph(MemoProcessState)
workflow.add_node("classify", classify_node)
workflow.add_node("extract", extract_tags_entities_node)
workflow.add_node("relate", find_relations_node)
workflow.add_node("persist", write_graph_node)

workflow.set_entry_point("classify")
workflow.add_edge("classify", "extract")
workflow.add_edge("extract", "relate")
workflow.add_edge("relate", "persist")
workflow.add_edge("persist", END)

app = workflow.compile()
```

### 4.3 速记模块

速记和事件的处理流程不同：

**速记（quick_note）处理流程：**
1. 用户输入内容 → 存入 MySQL
2. 触发 Celery 异步任务
3. LangGraph Agent 执行：
   - 查询用户现有的分类树和标签（从 Neo4j）
   - 根据现有分类匹配最合适的分类
   - 从内容中提取标签（优先复用已有标签）
   - 从内容中提取实体
   - 用提取的实体和标签去 Neo4j 查询相关内容
   - 根据相关内容判断关联强度，建立 RELATED_TO 关系
   - 如果内容涉及已有事件，建立 LINKED_TO 关系
4. 将所有图谱数据写入 Neo4j

**事件（event）处理流程：**
1. 用户创建事件 → 存入 MySQL
2. 触发 Celery 异步任务
3. LangGraph Agent 执行：
   - 对事件内容进行深度分析（提取关键词、意图、时间范围等）
   - 全量扫描用户的所有速记和事件（通过 embedding 向量检索 + 图谱遍历）
   - Agent 自主决策哪些内容与该事件相关
   - 建立关联关系并标注关联原因
4. 写入 Neo4j

```python
# 事件关联 Agent 的 Tool 定义
from langchain_core.tools import tool

@tool
def search_memos_by_embedding(query: str, user_id: int, top_k: int = 20) -> list[dict]:
    """通过语义相似度搜索用户的速记"""
    ...

@tool
def search_by_entity(entity_name: str, user_id: int) -> list[dict]:
    """通过实体名称在知识图谱中搜索相关内容"""
    ...

@tool
def search_by_tag(tag_name: str, user_id: int) -> list[dict]:
    """通过标签搜索相关内容"""
    ...

@tool
def search_by_category(category_name: str, user_id: int) -> list[dict]:
    """通过分类搜索相关内容"""
    ...

@tool
def create_relation(source_id: int, target_id: int, 
                    relation_type: str, score: float, reason: str):
    """在两个节点之间创建关联关系"""
    ...

# Agent 组装
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent

llm = ChatOpenAI(model="gpt-4o")
tools = [search_memos_by_embedding, search_by_entity, 
         search_by_tag, search_by_category, create_relation]

event_agent = create_react_agent(
    llm, tools,
    state_modifier="你是一个知识关联专家。当用户新增一个事件时，"
                   "你需要综合使用多种搜索工具，找出所有可能相关的速记和事件，"
                   "并为它们建立关联关系。关联时要给出关联度评分和原因。"
)
```

### 4.4 录音模块

```
前端录音 (MediaRecorder API)
    │
    │ WebSocket 流式传输 / 录完后上传
    ▼
FastAPI 接收音频
    │
    │ 调用 faster-whisper
    ▼
语音转文字
    │
    │ 文字进入速记处理流程
    ▼
存储（MySQL 存原文 + 音频URL，Neo4j 存图谱）
```

```python
# faster-whisper 服务示例
from faster_whisper import WhisperModel

model = WhisperModel("large-v3", device="cuda", compute_type="float16")

async def transcribe(audio_path: str) -> str:
    segments, info = model.transcribe(audio_path, language="zh")
    return "".join([segment.text for segment in segments])
```

### 4.5 搜索模块

搜索采用混合检索策略，通过 LangChain Agent 协调多种查询方式：

```
用户查询
    │
    ▼
LangChain 搜索 Agent
    │
    ├── 工具1: Neo4j 向量搜索（语义相似度）
    │     CALL db.index.vector.queryNodes('memo_embeddings', 10, $embedding)
    │
    ├── 工具2: Neo4j 全文搜索（关键词匹配）
    │     CALL db.index.fulltext.queryNodes('memoContent', $query)
    │
    ├── 工具3: GraphCypherQAChain（自然语言转图查询）
    │     "找到与Python相关的所有学习笔记" → MATCH (m:Memo)-[:HAS_TAG]->(t:Tag {name:'Python'}) RETURN m
    │
    ├── 工具4: 多跳图遍历（关系链探索）
    │     从某个实体出发，沿关系链查找 N 跳内的相关内容
    │
    └── 结果融合 + LLM 排序 + 返回
```

```python
from langchain_neo4j import GraphCypherQAChain, Neo4jGraph

graph = Neo4jGraph(url="bolt://localhost:7687", username="neo4j", password="xxx")

cypher_chain = GraphCypherQAChain.from_llm(
    llm=ChatOpenAI(model="gpt-4o"),
    graph=graph,
    verbose=True,
    allow_dangerous_requests=True
)

# 用户问："我上个月关于Python的笔记有哪些？"
# Agent 会自动生成 Cypher 查询并执行
```

### 4.6 展示模块

围绕两个核心维度展示：

**维度一：事件视图**
- 所有事件以看板/列表形式展示
- 每个事件可展开查看关联的速记
- 事件之间的关联以连线方式呈现
- 使用 react-force-graph 做关系图可视化

**维度二：时间线视图**
- 按时间轴排列所有速记和事件
- 支持按日/周/月粒度切换
- 同一时间段的内容聚合展示
- 时间线上标注重要事件节点

## 五、定时任务设计

使用 Celery Beat 做定时调度，Celery Worker 执行任务：

| 任务 | 频率 | 说明 |
|------|------|------|
| 标签共现计算 | 每天凌晨 | 统计标签共现关系，更新 Tag 节点间的 CO_OCCURS 权重 |
| 事件关联刷新 | 每 6 小时 | 对最近新增的速记，重新检查是否有遗漏的事件关联 |
| embedding 更新 | 实时 + 每天全量 | 新内容实时生成 embedding，每天全量检查缺失 |
| 社区检测 | 每周 | 使用 Neo4j GDS 的 Leiden 算法对内容做社区聚类 |
| 缓存预热 | 每天上午 | 预加载热门页面的缓存数据 |

```python
# Celery 任务示例
from celery import Celery
from celery.schedules import crontab

celery_app = Celery('quickmemo', broker='redis://localhost:6379/0')

@celery_app.task
def compute_tag_cooccurrence():
    """计算标签共现关系"""
    ...

@celery_app.task
def refresh_event_relations():
    """刷新事件关联关系"""
    ...

# Celery Beat 配置
celery_app.conf.beat_schedule = {
    'compute-tag-cooccurrence': {
        'task': 'tasks.compute_tag_cooccurrence',
        'schedule': crontab(hour=2, minute=0),  # 每天凌晨 2 点
    },
    'refresh-event-relations': {
        'task': 'tasks.refresh_event_relations',
        'schedule': crontab(hour='*/6'),  # 每 6 小时
    },
}
```

## 六、部署方案

```yaml
# docker-compose.yml
version: '3.8'

services:
  mysql:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: secret
      MYSQL_DATABASE: quickmemo
    volumes:
      - mysql-data:/var/lib/mysql

  neo4j:
    image: neo4j:5.15
    environment:
      NEO4J_AUTH: neo4j/password
    volumes:
      - neo4j-data:/data
    ports:
      - "7474:7474"
      - "7687:7687"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  backend:
    build: ./backend
    depends_on:
      - mysql
      - neo4j
      - redis
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: mysql+mysqlconnector://...
      NEO4J_URI: bolt://neo4j:7687
      REDIS_URL: redis://redis:6379/0

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"

  celery-worker:
    build: ./backend
    command: celery -A worker worker -l info
    depends_on:
      - backend
      - redis

  celery-beat:
    build: ./backend
    command: celery -A worker beat -l info
    depends_on:
      - backend
      - redis

volumes:
  mysql-data:
  neo4j-data:
```

## 七、关键技术细节与注意事项

1. **嵌入模型选择**
   - 推荐使用 `text-embedding-3-small` (OpenAI) 或 `BGE-large-zh` (智源) 用于中文场景
   - embedding 维度: 1536 (OpenAI) / 1024 (BGE)
   - Neo4j Vector Index: Cosine 相似度

2. **LLM 选型**
   - 默认: GPT-4o-mini (性价比最高)
   - 结构化输出任务: GPT-4o (更稳定)
   - 如需本地部署: Qwen2.5-72B-Instruct 或 Llama-3.1-70B

3. **LangChain 结构化输出**
   - 所有需要从 LLM 提取结构化数据的场景都使用 `with_structured_output`
   - 定义清晰的 Pydantic Model 避免解析错误

4. **Neo4j 性能优化**
   - 为所有常用查询属性创建索引
   - 谨慎使用 FULLTEXT 索引，仅对需要全文搜索的字段使用
   - 大批量数据写入时使用 UNWIND 批量 Cypher

5. **成本控制**
   - embedding 缓存: 对重复内容复用 embedding
   - Agent 工具调用限制: 设置最大 tool calls 避免无限循环
   - 批量处理: Celery 任务尽量小批量处理，单次处理过多内容可能超时

6. **隐私保护**
   - 所有用户数据做逻辑隔离（user_id 隔离）
   - 可选的本地化部署方案（本地 LLM + 本地 Neo4j）
   - 录音文件加密存储

## 八、开发路线图

### Phase 1: 基础框架（2 周）
- 搭建前后端框架
- 完成用户注册/登录
- 基础速记 CRUD（仅 MySQL，暂不接入 Neo4j）

### Phase 2: 知识图谱基础（2 周）
- 集成 Neo4j
- 实现分类模块（一级+二级）
- LangChain 分类生成
- 基础图谱查询

### Phase 3: AI 智能化（3 周）
- 实现 LangGraph Agent 工作流
- 标签提取、实体抽取、关系发现
- 速记关联逻辑
- 事件关联逻辑

### Phase 4: 搜索与展示（2 周）
- 混合检索搜索
- 事件视图
- 时间线视图
- 图谱可视化

### Phase 5: 录音与高级功能（1 周）
- Whisper 集成
- 前端录音控件
- 社区检测与自动聚类

### Phase 6: 优化与部署（1 周）
- 性能优化
- Docker 部署
- 监控与日志

## 九、可参考的代码仓库

1. **langchain-neo4j**: https://github.com/langchain-ai/langchain-neo4j
2. **Microsoft GraphRAG**: https://github.com/microsoft/graphrag
3. **Neo4j LLM Graph Builder**: https://github.com/neo4j-labs/llm-graph-builder
4. **faster-whisper**: https://github.com/SYSTRAN/faster-whisper
5. **Tiptap**: https://github.com/ueberdosis/tiptap
6. **react-force-graph**: https://github.com/vasturiano/react-force-graph

## 十、总结

本方案的核心亮点：

1. **LangGraph 多节点 Agent 工作流**：将内容处理拆分为分类、抽取、关联、持久化多个节点，流程清晰、可复用
2. **四维度知识图谱**：分类、标签、关系、事件四维度交叉检索，满足用户多角度查找需求
3. **混合检索策略**：向量搜索 + 全文搜索 + 图查询 + 多跳遍历，搜索效果全面
4. **事件与速记的双重关联**：事件作为高维度的内容组织方式，速记作为快速记录，两者通过图关联形成知识网络
5. **全链路开源方案**：所有组件都有成熟的开源实现，可直接集成

这个方案完全基于你提出的技术栈（LangChain, Neo4j, MySQL, Redis, React），并充分利用了这些生态中的优秀开源项目。整体架构具备高扩展性，后续可以根据实际需求逐步优化和迭代。
